# /// script
# dependencies = [
#   "requests",
# ]
# ///
"""
Validate that all URLs from old docs (stable) resolve correctly in new docs (latest).

This script:
1. Downloads and parses objects.inv from stable docs
2. Parses objects.inv from newly built local docs
3. Scans the built site directory for all HTML files
4. Loads redirect mappings from mkdocs.yml
5. Validates that all old URLs are accessible in the new build
6. Generates a comprehensive report

Generated by Claude.
"""

import re
import zlib
from pathlib import Path
from typing import Dict, Set, List, Tuple
from collections import defaultdict
from io import BytesIO

import requests

# Configuration
STABLE_OBJECTS_INV_URL = "https://zarr.readthedocs.io/en/stable/objects.inv"
LOCAL_OBJECTS_INV = Path("site/objects.inv")
SITE_DIR = Path("site")
MKDOCS_CONFIG = Path("mkdocs.yml")


def parse_objects_inv(file_obj) -> Dict[str, str]:
    """
    Parse a Sphinx objects.inv file and extract object name -> URL mappings.

    Args:
        file_obj: File-like object containing objects.inv data

    Returns:
        Dictionary mapping object names to relative URLs
    """
    # Read header (4 lines)
    project_line = file_obj.readline()
    version_line = file_obj.readline()
    compression_line = file_obj.readline()
    empty_line = file_obj.readline()

    # Decompress the rest
    compressed = file_obj.read()
    decompressed = zlib.decompress(compressed)

    # Parse entries
    inventory = {}
    lines = decompressed.decode('utf-8').split('\n')

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # Format: name domain:role priority uri dispname
        # Example: Array py:class 1 api/array.html#zarr.Array -
        parts = line.split(None, 4)
        if len(parts) >= 4:
            name = parts[0]
            uri = parts[3]

            # Remove anchor if present (we care about the page, not the anchor)
            if '#' in uri:
                uri = uri.split('#')[0]

            # Handle special placeholder
            if uri == '-':
                continue

            inventory[name] = uri

    return inventory


def download_stable_inventory() -> Dict[str, str]:
    """Download and parse the stable docs objects.inv."""
    print(f"Downloading stable inventory from {STABLE_OBJECTS_INV_URL}...")
    try:
        # Use requests with User-Agent header
        response = requests.get(
            STABLE_OBJECTS_INV_URL,
            headers={'User-Agent': 'Mozilla/5.0 (compatible; zarr-docs-validator/1.0)'},
            timeout=30
        )
        response.raise_for_status()

        # Convert bytes to file-like object for parsing
        file_obj = BytesIO(response.content)
        return parse_objects_inv(file_obj)
    except Exception as e:
        print(f"Error downloading stable inventory: {e}")
        return {}


def load_local_inventory() -> Dict[str, str]:
    """Parse the locally built objects.inv."""
    print(f"Loading local inventory from {LOCAL_OBJECTS_INV}...")
    if not LOCAL_OBJECTS_INV.exists():
        print(f"ERROR: Local inventory not found at {LOCAL_OBJECTS_INV}")
        return {}

    with open(LOCAL_OBJECTS_INV, 'rb') as f:
        return parse_objects_inv(f)


def scan_site_files() -> Set[str]:
    """Scan the site directory for all HTML files and return relative paths."""
    print(f"Scanning {SITE_DIR} for HTML files...")
    html_files = set()

    if not SITE_DIR.exists():
        print(f"ERROR: Site directory not found at {SITE_DIR}")
        return html_files

    for html_file in SITE_DIR.rglob("*.html"):
        # Get relative path from site directory
        rel_path = html_file.relative_to(SITE_DIR)
        html_files.add(str(rel_path))

    print(f"Found {len(html_files)} HTML files")
    return html_files


def load_redirect_maps() -> Dict[str, str]:
    """Load redirect mappings from mkdocs.yml."""
    print(f"Loading redirects from {MKDOCS_CONFIG}...")
    redirects = {}

    if not MKDOCS_CONFIG.exists():
        print(f"WARNING: mkdocs.yml not found at {MKDOCS_CONFIG}")
        return redirects

    content = MKDOCS_CONFIG.read_text()

    # Find the redirect_maps section
    in_redirect_section = False
    for line in content.split('\n'):
        if 'redirect_maps:' in line:
            in_redirect_section = True
            continue

        if in_redirect_section:
            # Check if we've left the redirect section
            if line and not line.startswith(' ') and not line.startswith('\t'):
                break

            # Parse redirect mapping: 'old.md': 'new.md' or 'old.md': 'https://...'
            match = re.search(r"'([^']+)':\s*'([^']+)'", line)
            if match:
                old_path = match.group(1)
                new_path = match.group(2)

                # Convert .md to .html for URL comparison
                if old_path.endswith('.md'):
                    old_path = old_path[:-3] + '.html'

                redirects[old_path] = new_path

    print(f"Found {len(redirects)} redirect mappings")
    return redirects


def validate_urls(
    stable_inv: Dict[str, str],
    local_inv: Dict[str, str],
    site_files: Set[str],
    redirects: Dict[str, str]
) -> Tuple[List[dict], Dict[str, int]]:
    """
    Validate that all stable URLs are accessible in the new build.

    Returns:
        Tuple of (results list, statistics dict)
    """
    print("\nValidating URLs...")
    results = []
    stats = {
        'total': 0,
        'matched': 0,
        'redirected': 0,
        'missing': 0,
        'external': 0
    }

    # Get all unique URLs from stable inventory
    stable_urls = set(stable_inv.values())

    for url in sorted(stable_urls):
        stats['total'] += 1
        result = {
            'url': url,
            'status': 'UNKNOWN',
            'new_url': None,
            'note': ''
        }

        # Check if it's an external URL
        if url.startswith('http://') or url.startswith('https://'):
            result['status'] = 'EXTERNAL'
            result['note'] = 'External URL, skipped'
            stats['external'] += 1
            results.append(result)
            continue

        # Check direct match in site files
        if url in site_files:
            result['status'] = 'OK'
            result['new_url'] = url
            stats['matched'] += 1
            results.append(result)
            continue

        # Check if it's in redirects
        if url in redirects:
            redirect_target = redirects[url]
            result['status'] = 'REDIRECT'
            result['new_url'] = redirect_target
            result['note'] = f'Redirects to {redirect_target}'
            stats['redirected'] += 1
            results.append(result)
            continue


        # Not found
        result['status'] = 'MISSING'
        result['note'] = 'URL not found in new build'
        stats['missing'] += 1
        results.append(result)

    return results, stats


def print_report(results: List[dict], stats: Dict[str, int]):
    """Print a comprehensive validation report."""
    print("\n" + "=" * 80)
    print("VALIDATION REPORT")
    print("=" * 80)

    # Summary statistics
    print("\nüìä SUMMARY STATISTICS")
    print("-" * 80)
    print(f"Total URLs checked:        {stats['total']}")
    print(f"  ‚úÖ Matched (OK):         {stats['matched']}")
    print(f"  üîÄ Redirected:           {stats['redirected']}")
    print(f"  ‚ùå Missing:              {stats['missing']}")
    print(f"  üåê External (skipped):   {stats['external']}")

    # Calculate coverage
    accessible = stats['matched'] + stats['redirected']
    internal_total = stats['total'] - stats['external']
    if internal_total > 0:
        coverage = (accessible / internal_total) * 100
        print(f"\nüìà Coverage: {coverage:.1f}% ({accessible}/{internal_total})")

    # Show missing URLs
    missing = [r for r in results if r['status'] == 'MISSING']
    if missing:
        print(f"\n‚ùå MISSING URLS ({len(missing)})")
        print("-" * 80)
        for r in missing:
            print(f"  ‚Ä¢ {r['url']}")

    # Show redirects
    redirected = [r for r in results if r['status'] == 'REDIRECT']
    if redirected:
        print(f"\nüîÄ REDIRECTED URLS ({len(redirected)})")
        print("-" * 80)
        for r in redirected[:10]:  # Show first 10
            print(f"  ‚Ä¢ {r['url']} ‚Üí {r['new_url']}")
        if len(redirected) > 10:
            print(f"  ... and {len(redirected) - 10} more")

    # Show format changes
    format_changes = [r for r in results if r['status'] == 'OK' and 'format changed' in r['note']]
    if format_changes:
        print(f"\nüîÑ URL FORMAT CHANGES ({len(format_changes)})")
        print("-" * 80)
        for r in format_changes[:10]:  # Show first 10
            print(f"  ‚Ä¢ {r['url']} ‚Üí {r['new_url']}")
        if len(format_changes) > 10:
            print(f"  ... and {len(format_changes) - 10} more")

    print("\n" + "=" * 80)

    # Final verdict
    if stats['missing'] == 0:
        print("‚úÖ SUCCESS: All URLs from stable docs are accessible in new build!")
    else:
        print(f"‚ö†Ô∏è  WARNING: {stats['missing']} URLs are not accessible in new build")

    print("=" * 80 + "\n")


def main():
    """Main execution function."""
    print("Documentation URL Validation Tool")
    print("=" * 80 + "\n")

    # Step 1: Download stable inventory
    stable_inv = download_stable_inventory()
    if not stable_inv:
        print("ERROR: Could not load stable inventory. Aborting.")
        return 1
    print(f"  Loaded {len(stable_inv)} objects from stable docs")

    # Step 2: Load local inventory
    local_inv = load_local_inventory()
    if not local_inv:
        print("WARNING: Could not load local inventory")
    else:
        print(f"  Loaded {len(local_inv)} objects from local docs")

    # Step 3: Scan site files
    site_files = scan_site_files()
    if not site_files:
        print("WARNING: No site files found")

    # Step 4: Load redirects
    redirects = load_redirect_maps()

    # Step 5: Validate URLs
    results, stats = validate_urls(stable_inv, local_inv, site_files, redirects)

    # Step 6: Print report
    print_report(results, stats)

    # Return exit code based on results
    return 0 if stats['missing'] == 0 else 1


if __name__ == '__main__':
    exit(main())
